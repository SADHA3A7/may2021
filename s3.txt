S3 : Simple Storage Service : 

Object Based Storage :  Designed to store flat files. (pdf/docx, .exe, .msi) : GDrive : S3 
Block Based Storage : Designed to run OS/ applications.. : EBS, Instance Store
Storage over the network : (SAN/NAS) : Storage device available over the network, network resources can connect it and access the data..  EFS, FSx

--> S3 is Object Based Storage. We cannot install any OS or we cannot run any application in this s3 platform.
--> We are going to store all data in S3 "BUCKETS".
--> Bucket name should be unique.
--> We have unlimited data in s3 platform.
--> Defaultly we can create 100 buckets in AWS account. (Soft limit : We can raise ticket to increse this count).
--> Bucket Naming Limitations : 
	--> Bucket name should contains only lowercase letter. No uppercase.
	--> SHould not start . / Endwith . / Adjesent ..
	--> SHould not resemble IP address format.

--> We can upload/download/share the bucket data.
--> Object : Data uploading to s3 bucket.
--> Maximum Object size S3 supports : 5 TiB, Min Obj Size : 0/1 Byte
--> S3 is a global service. Does not required any region selection.

Object url : https://s3.regioncode.amazonaws.com/bucketname/objectname

Virtual Path : It won't work when we have . in the bucket names..
https://bucketname.s3.regioncode.amazonaws.com/objectname
https://bucketname.s3.amazonaws.com/objectname

https://1avinash.s3.ap-south-1.amazonaws.com/s3.txt

--> If we want to make any data publicly accesable, We need to edit Bucket level "public Access settings". (Block all public access : On)

--> Make object public, then we can access the file.

________________________________________________________________________________________

D: 22/05/2021

Block Public Access settings for this account : Use Amazon S3 Block public access settings to control the settings that allow public access to your data.


S3 Standard : Default storage class for our data. Data will be available immediately. Designed to store Frequently accessed data.
Data replicates across >= 3 AZs
Availability : 99.99%
Durability : 99.999999999% (11 9's)

Standard-IA (Infrequently Accessed) : We can store infreq accessed data. Data will be available immediately.
Data replicates across >= 3 AZs
Availability : 99.9%
Durability : 99.999999999% (11 9's)

Onezone-IA : We can store infreq accessed data. Data will be available immediately.
Data stores only in 1 AZ only
Availability : 99.5%
Durability : 99.999999999% (11 9's)

S3 Glcier : We can archieve data for longer durations. We cannot access the data immedeatly. When we required, we need to initialise the data restoration.  Data restoration takes Min-Hrs.
Data replicates across >= 3 AZs
Availability : 99.99%
Durability : 99.999999999% (11 9's)

S3 Glacier Deep Archieve : We can archieve data for longer durations. We cannot access the data immedeatly. When we required, we need to initialise the data restoration.  Data restoration takes Hours.
Data replicates across >= 3 AZs
Availability : 99.99%
Durability : 99.999999999% (11 9's)

S3 Intelligent Tiering : When we have unknown access patterns. 
Data replicates across >= 3 AZs
Availability : 99.9%
Durability : 99.999999999% (11 9's)

RRS (Redused Redundancy Storage) : Not recommanded.. Less durability. Chances to loss the data is more compare to another storage classes. TO store easily repodusable data, Non Mission critical data.. 
Data replicates across >= 3 AZs
Availability : 99.9%
Durability : 99.99%

GLacier Retrivals : 
Bulk retrieval : Typically within 5-12 hours.
Standard retrieval : Typically within 3-5 hours.
Expedited retrieval : Typically within 1-5 minutes when retrieving less than 250 MB. 

Free Tier : 5 gb s3 standard storage.
2000 PUT (upload) Operations and 20,000 GET (open/download) operations. Value reset everymonth 1st. 

Data retrival cost involved for : standard-IA, onezone-IA, Glacier, G Deep archieve..

__
Versioning : 
--> We can track all changes happening on this file.
--> If we accidentally deleted the object, we can get it back if versioning is enabled.

Most recent uploaded object called as "Current Object / Latest object"

(version: hide)
When versioning is enabled, If we delete the object, we will get the "Delete Marker", Delete the Delete marker to get this object back to s3 bucket.

(version: show)
Whatever we deletes, we won;t get any delate marker. Object deletes permanently.


delete : Create a Delete Marker.
permanently delete : THis object deletes permanently, without delete marker.

________________________________________________________________________________________

D: 24/05/2021

LCR : LifeCycle Management Rule : 

expire : We will get a Delete marker.

CRR/SRR : 
--> Source bucket and Destination bucket should enabled with Versioning.
--> If source bucket and destination bucket is in same region : SRR (Same region replicaiton)
--> If source and destination buckets are in diff region : CRR (Cross region replication).

RTC : Replication Time Control : Boost up the replication process. Max of data replicates within 15 min. 

--> Existing objects won't replicate to destination bucket. ALl future/subsequent uploads will replicate to destination bucket.

______
Enable Billing information access to IAM User/role : Login as root user --> Myaccount --> ENable.
Enable FREE TIER Limit Alerts : 
My Account --> Billing preferences --> Receive Free Tier Usage Alerts (Enable) and Provide email. 

Create a Billing Alarm to get notification when any of the aws resource start costing us.
Billing preference --> Receive Billing Alerts -->  Manage Billing Alerts  --> create a billing alarm.

________________________________________________________________________________________

D: 25/05/2021

Encryption : 

--> In-Transit Encryption
	--> S3 Uses SSL / TLS Certificates. THis enabled by defaultly.

--> Server Side Encryption (SSE) / At-Rest 
	--> SSE - S3 : Key material generated and managed by S3 platform. Whoever have valid access on s3 platform they can decrypt the data.

    --> SSE - KMS (Key Management Service): 
	--> aws/s3 : (Default Master Key / DMK) : Key material generated and managed by KMS Service. Whoever have valid access on s3 platform they can decrypt the data.
	--> Customer managed keys (CMK) : Key material generated and managed by KMS Service. We need to provide required permissions on Encryption key to IAM users/Roles, then only they can decrypt the data. (NO FREE TIER ELIGIBILITY : 1$/Month)

	--> SSE - C (Customer Provided) : We/customer need to generate the key material and need to upload the key material to KMS service, then we can use as regular kms key. We need to provide required permissions on Encryption key to IAM users/Roles, then only they can decrypt the data. (NO FREE TIER ELIGIBILITY : 1$/Month)


Client SIde Encryption : When client don;t want to send any unencrypted data to any of the outside env, We can use this CSE. AWS is not responsible for this CSE. (truecrypt, securedata)

_____
KMS Defaultly generates the Key for the services we are using (Ex: aws/s3, aws/ebs, aws/efs). These keys we cannot delete, It is managed by AWS KMS service.

Step 1 : Symmetric 
Symmetric : A single encryption key that is used for both encrypt and decrypt operations
Asymmetric : A public and private key pair that can be used for encrypt/decrypt or sign/verify operat.

Step 2: provid name and descryption.

Step 3: Define key administrative permissions. 
	--> Who can administrate this encryption key. (Delete, Provide permission to users, key disable/enable).

Step 4 : Define key usage permissions
	--> Who can use this key. Who can decrypt the data. 

Step 5 : Review and create.

___________


Intelligent-Tiering Archive configurations : This feature is similar to Glcier and Glacier Deep archieve, but intelligence added here. THis applicable to Intelligent tier storage class data only. 

Archive Access tier : When enabled, Intelligent-Tiering will automatically move objects that haven’t been accessed for a minimum of 90 days to the Archive Access tier. Restore takes 3-5 Hrs.

Deep Archive Access tier : When enabled, Intelligent-Tiering will automatically move objects that haven’t been accessed for a minimum of 180 days to the Deep Archive Access tier. Restore takes min of 12 Hrs.

____________

Server access logging : We can enable logging for this individual s3 bucket. 

In CLoudtrail: We have DATA Events, This feature can log all the information about the s3 bucket. (all current s3 buckets and future s3 buckets also).

_________________________________________________________________________________________

D: 26/05/2021

Bucket policy : 

1avinash bucket

IAMuser1 : S3FullAccess : Okay to have full acces son all resources 
IAMuser2 : S3FullAccess : I don't want to allow this user to Delete "1avinash", Deny PUT operations on this bucket.

Policy Generator URL : https://awspolicygen.s3.amazonaws.com/policygen.html

Policy type : S3 bucket

effect : ALLOW / DENY	: Deny
Principal : For what IAM user/group you want to allow/deny : arn:aws:iam::518084852393:user/user2

Actions : DeleteBucket

Resources arn : on what bucket you want to apply : arn:aws:s3:::1avinash

Bucket level : arn:aws:s3:::1avinash
Object level : arn:aws:s3:::1avinash/*

_____________

Event notifications: 

--> SNS : Simple notification Service
--> SQS : Simeple queue service
--> Lambda

Navigate to SNS, Create a SNS topic, Add subscribers. (Modify accesspolicy : everyone)
(1000 emails)

___

Transfer acceleration : Boost up the data transfer. It uses neasrby edge locations to perform data transfer. No guarantee to get positive results with this feature, We can run speed comparison tool to te the result. 
--> If we have . in bucket name, we cannot use this feature.

https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html?region=ap-south-1&origBucketName=1avinash

___

Requester pays : Instead of bucket owner, data requester will get charged for the req & data transfer. 

_______________________________________________________________________________________

D: 27/05/2021

Object Lock : Protect our data. WHiloe creating bucket we need to enable this feature.
--> Versioning must be enabled to use object lock.

Data retention period : 2 days.. 


Governance : Users with specific IAM permissions can overwrite or delete protected object versions during the retention period.

Compliance : No users can overwrite or delete protected object versions during the retention period.

__________

Static Website hosting : 
--> Bucket name should be same as Domain name (In future if you have idea to map domain name)
--> All data must have public read access. 
--> Supports 3500 Req/Sec
--> Index.html , error.html

Http status codes : 
2XX : OK/Success
3XX : Redirection
4XX : Client Side errors
5XX : Server Side errors

_________

Cloudwatch : Monitoring service in our AWS environment. It generates graphs on our resources.

Storage Class Analysis : Based on our access patterns, Atorage class analysis report suggest us to choose the appropriate stirage class for the data.
--> CSV

Inventory configurations : This report provide all objects and metadata information. We can generate Weekly / Daily inventory reports.

Cross-origin resource sharing (CORS) : 

Access control list (ACL) : 
TO share s3 data, we need to have receivers cananical id.

______________

Performance : 

--> Increase the randomness in the object names.
--> Use the prefixes (folders) to manage the data.

--> 3500 PUT/Sec, 5500 GET/Sec we will get if we are directly storing all the data in s3 bucket.

--> 3500 PUT/Sec, 5500 GET/Sec we will get Per Prefix.

If you required 35000 PUT/Sec, Create 10 Prefixes and upload the data to the prefixes.

_____________

Consistency Mechanism : 

Read after write consistency for PUT of new objects.
Eventual consistency for Overwride of PUT object and Delete object. (it might take some seconds to delete/update the existing backend copies).

_____________


https://www.udemy.com/course/linuxwithavinash/?couponCode=MAY1AVINASH

https://www.udemy.com/course/jenkinswithavinash/?couponCode=MAY1AVINASH

https://www.udemy.com/course/gitbyavinash/?referralCode=F7D62CDB4D61EADE1CC7

________________________________________________________________________________________

D: 28/05/2021

AWS SnowFamily : Create a Job to get the device.

AWS Snowcone : 8 TB
AWS Snowball : 80-100 TB 
AWS SNowball Edge : 40 - 100 TB
AWS Snowmobile : PB Scale container

_____________________________________________________________________________________







































































